data:
  root: "./datasets/LSUI/"
  train_dir: "train"
  test_dir: "test"
  input_dir: "input"
  target_dir: "GT"  
  image_size: 256
  batch_size: 4
  num_workers: 4
  max_len: 1  

model:
  inp_channels: 3
  out_channels: 3
  d: 16                    
  num_blocks: [2, 2, 2, 3] 
  num_refinement: 2       
  heads: [2, 4, 8, 16]    
  ffn_exp: 2.0          
  
  loss_cfg:
    weights:
      l1: 1.0             
      perc: 0.01          # Reduced from 0.02 (was causing exploding gradients)
      ssim: 1.0         # Increased from 0.5
      grad: 0.5            # Increased from 0.1     

training:
  model_dir: "./outputs_LSUI"
  epochs: 800
  batch_size: 8          # Increased batch size for stability
  learning_rate: 0.0001  # Reduced learning rate
  weight_decay: 0.0001
  warmup_epochs: 10       # More warmup epochs
  save_freq: 10
  eval_freq: 5
  print_freq: 100
  gradient_clip: 0.5     # Reduced gradient clipping

  optimization:
    optimizer:
      name: "AdamW"
      lr: 0.0001        # Updated to match training lr
      weight_decay: 0.0001
      betas: [0.9, 0.999]

    scheduler:
      name: "CosineAnnealingLR"
      T_max: 800
      eta_min: 0.00001

evaluation:
  metrics: ["psnr", "ssim", "lpips"]
  save_images: true
  save_high_res: false 